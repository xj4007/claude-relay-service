/**
 * æµ‹è¯• anyrouter-heibai è´¦æˆ·çš„å®é™… SSE å“åº”æ ¼å¼
 * ç”¨äºè¯Šæ–­ç¼“å­˜ token åˆ†é…é—®é¢˜
 */

const axios = require('axios')
const logger = require('../src/utils/logger')

async function testAnyrouterHeibaiResponse() {
  try {
    // ğŸ”§ é…ç½®ï¼šè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    const ACCOUNT_API_URL = 'https://your-anyrouter-heibai-url.com/v1/messages' // æ›¿æ¢ä¸ºå®é™…URL
    const ACCOUNT_API_KEY = 'your-api-key' // æ›¿æ¢ä¸ºå®é™…API Key
    const TEST_MODEL = 'claude-haiku-4-5-20251001'

    logger.info('ğŸ§ª Starting anyrouter-heibai SSE response test...')
    logger.info(`ğŸ“ API URL: ${ACCOUNT_API_URL}`)
    logger.info(`ğŸ¯ Model: ${TEST_MODEL}`)

    // ğŸ¯ æ„é€ æµ‹è¯•è¯·æ±‚ï¼ˆé¦–æ¬¡è¯·æ±‚ï¼Œåº”è¯¥åˆ›å»ºç¼“å­˜ï¼‰
    const requestBody = {
      model: TEST_MODEL,
      max_tokens: 100,
      stream: true,
      messages: [
        {
          role: 'user',
          content: 'Hello, this is a test message for cache analysis.'
        }
      ],
      // ğŸ”‘ å¯ç”¨æç¤ºç¼“å­˜
      system: [
        {
          type: 'text',
          text: 'You are a helpful assistant. This is a cached system prompt for testing.',
          cache_control: { type: 'ephemeral' }
        }
      ]
    }

    logger.info('ğŸ“¤ Sending test request with cache_control...')

    // å‘é€æµå¼è¯·æ±‚
    const response = await axios({
      method: 'POST',
      url: ACCOUNT_API_URL,
      data: requestBody,
      headers: {
        'Content-Type': 'application/json',
        'anthropic-version': '2023-06-01',
        'x-api-key': ACCOUNT_API_KEY,
        'anthropic-beta': 'prompt-caching-2024-07-31,output-token-statistics-2024-11-04'
      },
      responseType: 'stream',
      validateStatus: () => true
    })

    if (response.status !== 200) {
      logger.error(`âŒ Request failed with status ${response.status}`)
      return
    }

    logger.info('âœ… Request successful, parsing SSE stream...')

    let messageStartUsage = null
    let messageDeltaUsage = null
    let buffer = ''

    // å¤„ç†æµæ•°æ®
    response.data.on('data', (chunk) => {
      const chunkStr = chunk.toString()
      buffer += chunkStr

      const lines = buffer.split('\n')
      buffer = lines.pop() || ''

      for (const line of lines) {
        // è§£æ SSE æ•°æ®
        let dataLine = null
        if (line.startsWith('data: ') && line.length > 6) {
          dataLine = line.slice(6)
        } else if (line.startsWith('data:') && line.length > 5) {
          dataLine = line.slice(5)
        }

        if (dataLine) {
          try {
            const data = JSON.parse(dataLine)

            // ğŸ” æ•è· message_start äº‹ä»¶
            if (data.type === 'message_start' && data.message && data.message.usage) {
              messageStartUsage = data.message.usage
              logger.info('ğŸ“Š [message_start] Usage data:')
              logger.info(JSON.stringify(messageStartUsage, null, 2))
            }

            // ğŸ” æ•è· message_delta äº‹ä»¶
            if (data.type === 'message_delta' && data.usage) {
              messageDeltaUsage = data.usage
              logger.info('ğŸ“Š [message_delta] Usage data:')
              logger.info(JSON.stringify(messageDeltaUsage, null, 2))
            }
          } catch (e) {
            // å¿½ç•¥é JSON è¡Œ
          }
        }
      }
    })

    response.data.on('end', () => {
      logger.info('\nâœ… Stream completed')

      // ğŸ¯ åˆ†æç»“æœ
      logger.info('\nğŸ“‹ === Final Analysis ===')

      if (messageStartUsage) {
        logger.info('\nğŸ”¹ message_start usage:')
        logger.info(`  input_tokens: ${messageStartUsage.input_tokens || 0}`)
        logger.info(
          `  cache_creation_input_tokens: ${messageStartUsage.cache_creation_input_tokens || 0}`
        )
        logger.info(`  cache_read_input_tokens: ${messageStartUsage.cache_read_input_tokens || 0}`)
      } else {
        logger.warn('âš ï¸ No message_start usage data found')
      }

      if (messageDeltaUsage) {
        logger.info('\nğŸ”¹ message_delta usage:')
        logger.info(`  input_tokens: ${messageDeltaUsage.input_tokens || 0}`)
        logger.info(`  output_tokens: ${messageDeltaUsage.output_tokens || 0}`)
        logger.info(
          `  cache_creation_input_tokens: ${messageDeltaUsage.cache_creation_input_tokens || 0}`
        )
        logger.info(`  cache_read_input_tokens: ${messageDeltaUsage.cache_read_input_tokens || 0}`)
      } else {
        logger.warn('âš ï¸ No message_delta usage data found')
      }

      // ğŸ¯ è¯Šæ–­é—®é¢˜
      logger.info('\nğŸ” === Problem Diagnosis ===')

      if (messageStartUsage) {
        const hasCacheCreation = (messageStartUsage.cache_creation_input_tokens || 0) > 0
        const hasCacheRead = (messageStartUsage.cache_read_input_tokens || 0) > 0

        if (hasCacheCreation && hasCacheRead) {
          logger.error('âŒ PROBLEM DETECTED: First request has BOTH cache_creation AND cache_read!')
          logger.error(
            '   This is incorrect - first request should only have cache_creation, not cache_read.'
          )
        } else if (hasCacheCreation && !hasCacheRead) {
          logger.info('âœ… CORRECT: First request has cache_creation but no cache_read')
        } else if (!hasCacheCreation && hasCacheRead) {
          logger.warn(
            'âš ï¸ UNEXPECTED: First request has cache_read but no cache_creation (should be a cache hit, not first request)'
          )
        } else {
          logger.info('â„¹ï¸ No cache tokens found (caching may not be enabled)')
        }
      }

      logger.info('\nâœ… Test completed')
      process.exit(0)
    })

    response.data.on('error', (error) => {
      logger.error(`âŒ Stream error: ${error.message}`)
      process.exit(1)
    })
  } catch (error) {
    logger.error('âŒ Test failed:', error.message)
    if (error.response) {
      logger.error(`Status: ${error.response.status}`)
      logger.error(`Data: ${JSON.stringify(error.response.data)}`)
    }
    process.exit(1)
  }
}

// è¿è¡Œæµ‹è¯•
testAnyrouterHeibaiResponse()
