const crypto = require('crypto')
const redis = require('../models/redis')
const logger = require('../utils/logger')
const requestQueue = require('../utils/requestQueue')

/**
 * ÂìçÂ∫îÁºìÂ≠òÊúçÂä°
 * Áî®‰∫éÁºìÂ≠òÂÆ¢Êà∑Á´ØÊñ≠ÂºÄ‰ΩÜ‰∏äÊ∏∏ÊàêÂäüËøîÂõûÁöÑÂìçÂ∫î
 * ÈÅøÂÖçÂÆ¢Êà∑Á´ØÈáçËØïÊó∂ÈáçÂ§çËØ∑Ê±Ç‰∏äÊ∏∏
 *
 * Êñ∞ÂäüËÉΩÔºö
 * - ËØ∑Ê±ÇÂéªÈáçÂíåÁ≠âÂæÖÂÖ±‰∫´ÔºàÂ§ö‰∏™Áõ∏ÂêåËØ∑Ê±ÇÂÖ±‰∫´‰∏Ä‰∏™‰∏äÊ∏∏Ë∞ÉÁî®Ôºâ
 * - Â¢ûÂä†TTLÂà∞5ÂàÜÈíü
 */
class ResponseCacheService {
  constructor() {
    this.CACHE_PREFIX = 'response_cache:'
    this.STREAM_CACHE_PREFIX = 'stream_cache:'
    this.DEFAULT_TTL = 300 // 5ÂàÜÈíüÔºà‰ªé180ÁßíÊîπ‰∏∫300ÁßíÔºâ
    this.MAX_CACHE_SIZE = 5 * 1024 * 1024 // 5MB
  }

  /**
   * ÁîüÊàêÁºìÂ≠òÈîÆÔºàÂü∫‰∫éËØ∑Ê±ÇÂÜÖÂÆπÁöÑÂîØ‰∏ÄÂìàÂ∏åÔºâ
   * @param {Object} requestBody - ËØ∑Ê±Ç‰Ωì
   * @param {string} model - Ê®°ÂûãÂêçÁß∞
   * @returns {string} - ÁºìÂ≠òÈîÆ
   */
  generateCacheKey(requestBody, model) {
    try {
      // ÊûÑÂª∫ÁºìÂ≠òÈîÆÁöÑÂÜÖÂÆπÔºàÂåÖÂê´ÊâÄÊúâÂΩ±ÂìçËæìÂá∫ÁöÑÂèÇÊï∞Ôºâ
      // ‚ö†Ô∏è ÂøÖÈ°ªÊåâÂõ∫ÂÆöÈ°∫Â∫èÊûÑÂª∫ÔºåÁ°Æ‰øùÁõ∏ÂêåÂÜÖÂÆπÁîüÊàêÁõ∏ÂêåÂìàÂ∏å
      const cacheContent = {
        model: model,
        messages: requestBody.messages || [],
        system: requestBody.system || '',
        max_tokens: requestBody.max_tokens,
        temperature: requestBody.temperature,
        top_p: requestBody.top_p,
        top_k: requestBody.top_k,
        stop_sequences: requestBody.stop_sequences,
        // ‰∏çÂåÖÂê´ metadata Âíå streamÔºåÂõ†‰∏∫Ëøô‰∫õ‰∏çÂΩ±ÂìçËæìÂá∫ÂÜÖÂÆπ
      }

      // üîß ‰ΩøÁî®Á®≥ÂÆöÁöÑÂ∫èÂàóÂåñÊñπÂºèÔºàÊåâÈîÆÊéíÂ∫èÔºâ
      const stableJson = JSON.stringify(cacheContent, Object.keys(cacheContent).sort())

      // ÁîüÊàê SHA256 ÂìàÂ∏å
      const hash = crypto.createHash('sha256').update(stableJson).digest('hex').substring(0, 32)

      logger.debug(`üìã Cache key generated: ${hash}`)
      return hash
    } catch (error) {
      logger.error(`‚ùå Failed to generate cache key: ${error.message}`)
      return null
    }
  }

  /**
   * Ê£ÄÊü•ÁºìÂ≠òÊòØÂê¶Â≠òÂú®ÔºàÈùûÊµÅÂºèÔºâ
   * @param {string} cacheKey - ÁºìÂ≠òÈîÆ
   * @returns {Object|null} - ÁºìÂ≠òÁöÑÂìçÂ∫îÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôËøîÂõû null
   */
  async getCachedResponse(cacheKey) {
    if (!cacheKey) return null

    try {
      const client = redis.getClientSafe()
      const redisKey = `${this.CACHE_PREFIX}${cacheKey}`
      const cached = await client.hgetall(redisKey)

      if (!cached || !cached.body) {
        logger.debug(`üìã Cache miss: ${cacheKey}`)
        return null
      }

      // Ëß£ÊûêÁºìÂ≠òÁöÑÂìçÂ∫î
      const response = {
        statusCode: parseInt(cached.statusCode) || 200,
        headers: JSON.parse(cached.headers || '{}'),
        body: JSON.parse(cached.body),
        usage: cached.usage ? JSON.parse(cached.usage) : null,
        cachedAt: parseInt(cached.cachedAt) || Date.now()
      }

      logger.info(
        `üéØ Cache hit: ${cacheKey} | Cached ${Math.floor((Date.now() - response.cachedAt) / 1000)}s ago`
      )
      return response
    } catch (error) {
      logger.error(`‚ùå Failed to get cached response: ${error.message}`)
      return null
    }
  }

  /**
   * üÜï Ëé∑ÂèñÁºìÂ≠òÊàñÊâßË°åËØ∑Ê±ÇÔºàÂ∏¶ËØ∑Ê±ÇÂéªÈáçÂíåÁ≠âÂæÖÂÖ±‰∫´Ôºâ
   * Â¶ÇÊûúÁºìÂ≠òÂ≠òÂú®ÔºåÁõ¥Êé•ËøîÂõûÁºìÂ≠ò
   * Â¶ÇÊûúÊ≠£Âú®ËØ∑Ê±Ç‰∏≠ÔºåÁ≠âÂæÖÂπ∂ÂÖ±‰∫´ÁªìÊûú
   * Â¶ÇÊûúÈÉΩÊ≤°ÊúâÔºåÊâßË°åÊñ∞ËØ∑Ê±ÇÂπ∂ÁºìÂ≠ò
   *
   * @param {string} cacheKey - ÁºìÂ≠òÈîÆ
   * @param {Function} fetchFn - ËØ∑Ê±ÇÂáΩÊï∞ async () => response
   * @param {number} ttl - ÁºìÂ≠òTTLÔºàÁßíÔºâ
   * @returns {Promise<Object>} - ÂìçÂ∫îÂØπË±°
   */
  async getOrFetchResponse(cacheKey, fetchFn, ttl = this.DEFAULT_TTL) {
    if (!cacheKey) {
      // Ê≤°ÊúâÁºìÂ≠òÈîÆÔºåÁõ¥Êé•ÊâßË°åËØ∑Ê±Ç
      return await fetchFn()
    }

    // 1. ÂÖàÊ£ÄÊü•ÁºìÂ≠ò
    const cached = await this.getCachedResponse(cacheKey)
    if (cached) {
      logger.info(`‚úÖ Returning cached response | CacheKey: ${cacheKey.substring(0, 16)}...`)
      return cached
    }

    // 2. Ê£ÄÊü•ÊòØÂê¶ÊúâÁõ∏ÂêåËØ∑Ê±ÇÊ≠£Âú®ËøõË°åÔºåÂ¶ÇÊûúÊúâÂàôÁ≠âÂæÖ
    // Â¶ÇÊûúÊ≤°ÊúâÔºåÂàôÊâßË°åÊñ∞ËØ∑Ê±Ç
    const result = await requestQueue.executeOrWait(cacheKey, async () => {
      logger.info(`üöÄ Executing new upstream request | CacheKey: ${cacheKey.substring(0, 16)}...`)

      // ÊâßË°åÂÆûÈôÖËØ∑Ê±Ç
      const response = await fetchFn()

      // ÁºìÂ≠òÊàêÂäüÁöÑÂìçÂ∫îÔºàÂè™ÁºìÂ≠ò2xxÂìçÂ∫îÔºâ
      if (response.statusCode >= 200 && response.statusCode < 300) {
        await this.cacheResponse(cacheKey, response, ttl)
        // Ê†áËÆ∞‰∏∫ÊàêÂäüÔºåËÆ©Á≠âÂæÖÁöÑËØ∑Ê±ÇÂÖ±‰∫´Ê≠§ÁªìÊûú
        return { success: true, response }
      } else {
        logger.debug(
          `‚ö†Ô∏è Not caching non-2xx response: ${response.statusCode} | CacheKey: ${cacheKey.substring(0, 16)}...`
        )
        // Ê†áËÆ∞‰∏∫Â§±Ë¥•ÔºåËÆ©Á≠âÂæÖÁöÑËØ∑Ê±ÇÈáçÊñ∞Â∞ùËØï
        return { success: false, response }
      }
    })

    // 3. Â¶ÇÊûúÊòØÂ§±Ë¥•ÂìçÂ∫îÔºåÁ≠âÂæÖÁöÑËØ∑Ê±ÇÂ∫îËØ•ÈáçÊñ∞Â∞ùËØïËÄå‰∏çÊòØÂÖ±‰∫´Â§±Ë¥•ÁªìÊûú
    if (!result.success) {
      logger.warn(
        `‚ö†Ô∏è Shared request failed (${result.response.statusCode}), waiting request will retry independently | CacheKey: ${cacheKey.substring(0, 16)}...`
      )
      // üîÑ ÈáçÊñ∞ÊâßË°åËØ∑Ê±ÇÔºàÂ∏¶ÈáçËØïÈÄªËæëÔºâÔºå‰∏çÂÖ±‰∫´Â§±Ë¥•ÁªìÊûú
      return await fetchFn()
    }

    return result.response
  }

  /**
   * ÁºìÂ≠òÂìçÂ∫îÔºàÈùûÊµÅÂºèÔºâ
   * @param {string} cacheKey - ÁºìÂ≠òÈîÆ
   * @param {Object} response - ÂìçÂ∫îÂØπË±°
   * @param {number} ttl - ËøáÊúüÊó∂Èó¥ÔºàÁßíÔºâ
   */
  async cacheResponse(cacheKey, response, ttl = this.DEFAULT_TTL) {
    if (!cacheKey) return

    try {
      const client = redis.getClientSafe()
      const redisKey = `${this.CACHE_PREFIX}${cacheKey}`

      // Ê£ÄÊü•ÂìçÂ∫îÂ§ßÂ∞è
      const bodySize = JSON.stringify(response.body).length
      if (bodySize > this.MAX_CACHE_SIZE) {
        logger.warn(
          `‚ö†Ô∏è Response too large to cache: ${(bodySize / 1024 / 1024).toFixed(2)}MB > ${this.MAX_CACHE_SIZE / 1024 / 1024}MB`
        )
        return
      }

      // Â≠òÂÇ®Âà∞ Redis Hash
      const cacheData = {
        statusCode: response.statusCode.toString(),
        headers: JSON.stringify(response.headers),
        body: JSON.stringify(response.body),
        usage: response.usage ? JSON.stringify(response.usage) : '',
        cachedAt: Date.now().toString(),
      }

      await client.hset(redisKey, cacheData)
      await client.expire(redisKey, ttl)

      logger.info(
        `üíæ Cached response: ${cacheKey} | Size: ${(bodySize / 1024).toFixed(2)}KB | TTL: ${ttl}s`
      )
    } catch (error) {
      logger.error(`‚ùå Failed to cache response: ${error.message}`)
    }
  }

  /**
   * Ê£ÄÊü•ÊµÅÂºèÁºìÂ≠òÊòØÂê¶Â≠òÂú®
   * @param {string} cacheKey - ÁºìÂ≠òÈîÆ
   * @returns {Array|null} - ÁºìÂ≠òÁöÑ chunks Êï∞ÁªÑÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôËøîÂõû null
   */
  async getCachedStream(cacheKey) {
    if (!cacheKey) return null

    try {
      const client = redis.getClientSafe()
      const redisKey = `${this.STREAM_CACHE_PREFIX}${cacheKey}`

      // Ê£ÄÊü•ÊòØÂê¶Â≠òÂú®‰∏îÂÆåÊï¥
      const metadata = await client.hgetall(`${redisKey}:meta`)
      if (!metadata || metadata.complete !== 'true') {
        logger.debug(`üìã Stream cache miss or incomplete: ${cacheKey}`)
        return null
      }

      // Ëé∑ÂèñÊâÄÊúâ chunks
      const chunks = await client.lrange(redisKey, 0, -1)
      if (!chunks || chunks.length === 0) {
        return null
      }

      logger.info(
        `üéØ Stream cache hit: ${cacheKey} | ${chunks.length} chunks | Cached ${Math.floor((Date.now() - parseInt(metadata.cachedAt)) / 1000)}s ago`
      )
      return chunks.map((chunk) => JSON.parse(chunk))
    } catch (error) {
      logger.error(`‚ùå Failed to get cached stream: ${error.message}`)
      return null
    }
  }

  /**
   * ÂºÄÂßãÁºìÂ≠òÊµÅÂºèÂìçÂ∫î
   * @param {string} cacheKey - ÁºìÂ≠òÈîÆ
   * @returns {Object} - ÁºìÂ≠òÊî∂ÈõÜÂô®ÂØπË±°
   */
  createStreamCacheCollector(cacheKey) {
    if (!cacheKey) return null

    const chunks = []
    let totalSize = 0
    let isComplete = false

    return {
      /**
       * Ê∑ªÂä†‰∏Ä‰∏™ chunk
       * @param {Object} chunk - SSE chunk ÂØπË±°
       */
      addChunk(chunk) {
        const chunkStr = JSON.stringify(chunk)
        const chunkSize = chunkStr.length

        // Ê£ÄÊü•Â§ßÂ∞èÈôêÂà∂
        if (totalSize + chunkSize > this.MAX_CACHE_SIZE) {
          logger.warn(`‚ö†Ô∏è Stream cache size limit reached, stopping collection`)
          return false
        }

        chunks.push(chunk)
        totalSize += chunkSize

        // Ê£ÄÊü•ÊòØÂê¶ÂÆåÊàê
        if (chunk.event === 'message_stop') {
          isComplete = true
        }

        return true
      },

      /**
       * ‰øùÂ≠òÂà∞ RedisÔºàÂè™ÊúâÂÆåÊï¥Êé•Êî∂Êâç‰øùÂ≠òÔºâ
       * @param {number} ttl - ËøáÊúüÊó∂Èó¥ÔºàÁßíÔºâ
       */
      async save(ttl = this.DEFAULT_TTL) {
        if (!isComplete) {
          logger.debug(`üìã Stream incomplete, not caching: ${cacheKey}`)
          return
        }

        try {
          const client = redis.getClientSafe()
          const redisKey = `${this.STREAM_CACHE_PREFIX}${cacheKey}`

          // Ê∏ÖÁ©∫ÊóßÊï∞ÊçÆÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
          await client.del(redisKey)
          await client.del(`${redisKey}:meta`)

          // Â≠òÂÇ®ÊâÄÊúâ chunks
          for (const chunk of chunks) {
            await client.rpush(redisKey, JSON.stringify(chunk))
          }

          // Â≠òÂÇ®ÂÖÉÊï∞ÊçÆ
          await client.hset(`${redisKey}:meta`, {
            complete: 'true',
            cachedAt: Date.now().toString(),
            chunkCount: chunks.length.toString(),
          })

          // ËÆæÁΩÆËøáÊúüÊó∂Èó¥
          await client.expire(redisKey, ttl)
          await client.expire(`${redisKey}:meta`, ttl)

          logger.info(
            `üíæ Cached stream: ${cacheKey} | ${chunks.length} chunks | Size: ${(totalSize / 1024).toFixed(2)}KB | TTL: ${ttl}s`
          )
        } catch (error) {
          logger.error(`‚ùå Failed to save stream cache: ${error.message}`)
        }
      },

      /**
       * Ëé∑ÂèñÊî∂ÈõÜÁä∂ÊÄÅ
       */
      getStats() {
        return {
          chunkCount: chunks.length,
          totalSize,
          isComplete,
        }
      },
    }
  }

  /**
   * Ê∏ÖÈô§ÊåáÂÆöÁöÑÁºìÂ≠ò
   * @param {string} cacheKey - ÁºìÂ≠òÈîÆ
   */
  async clearCache(cacheKey) {
    if (!cacheKey) return

    try {
      const client = redis.getClientSafe()
      await client.del(`${this.CACHE_PREFIX}${cacheKey}`)
      await client.del(`${this.STREAM_CACHE_PREFIX}${cacheKey}`)
      await client.del(`${this.STREAM_CACHE_PREFIX}${cacheKey}:meta`)
      logger.debug(`üóëÔ∏è Cleared cache: ${cacheKey}`)
    } catch (error) {
      logger.error(`‚ùå Failed to clear cache: ${error.message}`)
    }
  }

  /**
   * Ëé∑ÂèñÁºìÂ≠òÁªüËÆ°‰ø°ÊÅØ
   */
  async getStats() {
    try {
      const client = redis.getClientSafe()

      // ÁªüËÆ°ÈùûÊµÅÂºèÁºìÂ≠ò
      const responseCacheKeys = await client.keys(`${this.CACHE_PREFIX}*`)
      let totalResponseSize = 0
      for (const key of responseCacheKeys) {
        const body = await client.hget(key, 'body')
        if (body) totalResponseSize += body.length
      }

      // ÁªüËÆ°ÊµÅÂºèÁºìÂ≠ò
      const streamCacheKeys = await client.keys(`${this.STREAM_CACHE_PREFIX}*`)
      const streamCacheCount = streamCacheKeys.filter((k) => !k.endsWith(':meta')).length

      return {
        responseCacheCount: responseCacheKeys.length,
        responseCacheSizeMB: (totalResponseSize / 1024 / 1024).toFixed(2),
        streamCacheCount,
        ttlSeconds: this.DEFAULT_TTL,
        maxCacheSizeMB: this.MAX_CACHE_SIZE / 1024 / 1024,
      }
    } catch (error) {
      logger.error(`‚ùå Failed to get cache stats: ${error.message}`)
      return null
    }
  }
}

module.exports = new ResponseCacheService()
